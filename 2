// Exists only to make configs easier to feed into shell scripts
// Runs docker containers with resource in config
// Also cleans up after each run
// Also generated graphs on the data points as we want acc to the paper

// Pretty much a very useless orchestrator

package main

import (
	"bytes"
	"compress/gzip"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"os/exec"
	"strings"
   "strconv"
)

var overall_x_axis_verticals map[string][]float64
var overall_y_axis_verticals map[string][]float64

// No defining data models...takes time
// Equality between two maps, used to check is previous tsbs config is same as present to reduce time. This will probably cause too many problems lol
func map_equality(m1 map[string]interface{}, m2 map[string]interface{}) bool {
	if len(m1) == len(m2) {
		for k := range m1 {
			if m1[k].(string) == m2[k].(string) {
				continue
			} else {
				return false
			}
		}
		return true
	} else {
		return false
	}
}
func parse_load_results(stdout *bytes.Buffer,docker_cmd_opts map[string]interface{},run_cmd_opts map[string]interface{}){
   overall_x_axis_verticals["cpu"] = append(overall_y_axis_verticals["cpu"],docker_cmd_opts["cpu"].(float64))
   overall_x_axis_verticals["memory"] = append(overall_y_axis_verticals["cpu"],docker_cmd_opts["cpu"].(float64))
   overall_x_axis_verticals["workers"] = append(overall_y_axis_verticals["workers"],load_cmd_opts["workers"].(float64))
   fin := false
   single_test_records := [][]float64{} // we'll use this later
   //find that one line thats empty 
   for _,val := range strings.Split(stdout.String(),"\n"){
      line := strings.Trim(val,"\n")
      if !fin && line != ""{
         inner := []float64 {}
         for _,val :=  range strings.Split(line,","){
            ival , _ := strconv.ParseFloat(val,2)
            inner = append(inner,ival)
         }
         single_test_records = append(single_test_records,inner)
      }else if fin{
         sp := strings.Split(line,"(")
         if len(sp) == 1{
            continue 
         }else{
            sp2 := strings.Split(sp[1]," ")
            overall_y_axis_verticals[sp2[3]] = append(overall_y_axis_verticals[sp2[3]],sp2[2])
         }
      }else{
         fin = true
      }
   }

}
func generate_cmd_from_tsbs_config(cmd_opts map[string]interface{}) {
	os.Remove(fmt.Sprintf("/tmp/%s-data.gz", cmd_opts["target"]))
	f, _ := os.Create(fmt.Sprintf("/tmp/%s-data.gz", cmd_opts["target"]))
	defer f.Close()
	cmd_opts_str := fmt.Sprintf("--use-case=devops --seed=%s --scale=%s --timestamp-start=%s --timestamp-end=%s --log-interval=%s --format=%s", cmd_opts["seed"], cmd_opts["scale"], cmd_opts["start_date"], cmd_opts["end_date"], cmd_opts["log_interval"], cmd_opts["target"])
	var stderr bytes.Buffer

	cmd_ctx := exec.Command("./tsbs_generate_data", strings.Split(cmd_opts_str, " ")...)
	out, _ := cmd_ctx.StdoutPipe()
	gzw := gzip.NewWriter(f)
	defer gzw.Close()
	defer gzw.Flush()
	cmd_ctx.Stderr = &stderr
	fmt.Println("\t[CMD]", cmd_ctx.String())
	cmd_ctx.Start()
	io.Copy(gzw, out)
	err := cmd_ctx.Wait()
	if err != nil {
		fmt.Println("Error generating data", err, cmd_ctx.String())
		fmt.Println(stderr.String())
		panic(err)
	}

	os.Remove(fmt.Sprintf("/tmp/%s-query.gz", cmd_opts["target"]))
	f_q, _ := os.Create(fmt.Sprintf("/tmp/%s-query.gz", cmd_opts["target"]))
	defer f_q.Close()
	query_gen_cmd_opts := fmt.Sprintf("--use-case=devops --seed=%s --scale=%s --timestamp-start=%s --timestamp-end=%s --queries=%s --query-type=%s --format=%s", cmd_opts["seed"], cmd_opts["scale"], cmd_opts["start_date"], cmd_opts["end_date"], cmd_opts["queries"], cmd_opts["query_type"], cmd_opts["target"])

	cmd_ctx_q := exec.Command("./tsbs_generate_queries", strings.Split(query_gen_cmd_opts, " ")...)
	out_q, _ := cmd_ctx_q.StdoutPipe()
	gzw_q := gzip.NewWriter(f_q)
	defer gzw_q.Close()
	defer gzw_q.Flush()
	stderr.Truncate(0)
	cmd_ctx_q.Stderr = &stderr
	fmt.Println("\t[CMD]", cmd_ctx_q.String())
	cmd_ctx_q.Start()
	io.Copy(gzw_q, out_q)
	err = cmd_ctx_q.Wait()
	if err != nil {
		fmt.Println("Error generating query", err, cmd_ctx_q.String())
		fmt.Println(stderr.String())
		panic(err)
	}
}

func run_cmd_from_tsbs_config(cmd_opts map[string]interface{}, target string) {
   overall_y_axis_verticals = make(map[string][]float64)
   overall_x_axis_verticals = make(map[string][]float64)
   overall_x_axis_verticals["cpu"] = []float64{}
   overall_x_axis_verticals["memory"] = []float64{}
   overall_x_axis_verticals["workers"] = []float64{}
   overall_y_axis_verticals["metrics/sec"] = []float64{}
   overall_y_axis_verticals["rows/sec"] = []float64{}

	f_q, _ := os.Open(fmt.Sprintf("/tmp/%s-data.gz", target))
	ungzp, _ := gzip.NewReader(f_q)
	defer ungzp.Close()
	load_cmd_opts := ""
	var stderr bytes.Buffer
	var stdout bytes.Buffer
	// if cmd_opts["password"] != "" {
	// 	load_cmd_opts += "--password=" + cmd_opts["password"].(string) + " "
	// }
	//
	// if cmd_opts["username"] != "" {
	// 	load_cmd_opts += "--username=" + cmd_opts["username"].(string) + " "
	// }
	//
	// if cmd_opts["workers"] != "" {
	// 	load_cmd_opts += "--workers=" + cmd_opts["workers"].(string)
	// }
	for k := range cmd_opts {
		if cmd_opts[k] == "" {
			continue
		}
		load_cmd_opts += "--" + k + "=" + cmd_opts[k].(string) + " "
	}
	cat_cmd := exec.Command("cat", fmt.Sprintf("/tmp/%s-data.gz", target))
	gzip_cmd := exec.Command("gunzip")
	gzip_cmd.Stdin, _ = cat_cmd.StdoutPipe()
	cmd_ctx := exec.Command(fmt.Sprintf("./tsbs_load_%s", target), strings.Split(load_cmd_opts, " ")...)
	cmd_ctx.Stdin, _ = gzip_cmd.StdoutPipe()
   cmd_ctx.Stdout = &stdout
	fmt.Println("\t[CMD]", cmd_ctx.String())
	cmd_ctx.Stderr = &stderr
   cat_cmd.Start()
   gzip_cmd.Start()
	cmd_ctx.Start()
	err := cat_cmd.Wait()
	if err != nil {
		fmt.Println("Error running cat", err, cmd_ctx.String())
		fmt.Println(stderr.String())
		panic(err)
	}
	err = gzip_cmd.Wait()
	if err != nil {
		fmt.Println("Error running gzip", err, cmd_ctx.String())
		fmt.Println(stderr.String())
		panic(err)
	}
	err = cmd_ctx.Wait()
	if err != nil {
		fmt.Println("Error loading", err, cmd_ctx.String())
		fmt.Println(stderr.String())
		panic(err)
	}
	fmt.Println("done")
	fmt.Println(stdout.String())
}

func DockerBuildAndRun(dockerfile_path string, docker_image_name string, docker_config map[string]interface{}) string {
	var out bytes.Buffer
	var stderr bytes.Buffer

	cmd := fmt.Sprintf("build %s -t %s", dockerfile_path, docker_image_name)
	cmd_ctx := exec.Command("docker", strings.Split(cmd, " ")...)
	cmd_ctx.Stdout = &out
	cmd_ctx.Stderr = &stderr
	fmt.Println("\t[CMD]", cmd_ctx.String())
	err := cmd_ctx.Run()
	if err != nil {
		fmt.Println("[ERROR] Erorr building image", err, cmd)
		fmt.Println("[ERROR]", stderr.String())
		panic(err)
	}

	cmd = fmt.Sprintf("run -d -m %s --cpus=%s -p 9000:9000 %s:latest", docker_config["memory"], docker_config["cpus"], docker_image_name)
	// println(out.String())
	cmd_ctx = exec.Command("docker", strings.Split(cmd, " ")...)
	fmt.Println("\t[CMD]", cmd_ctx.String())
	out.Truncate(0)
	stderr.Truncate(0)
	cmd_ctx.Stdout = &out
	cmd_ctx.Stderr = &stderr
	err = cmd_ctx.Run()
	if err != nil {
		fmt.Println("[ERROR]", stderr.String())
		fmt.Println("[ERROR] Error running images, check docker daemon and port availability...")
		panic(err)
	}
	fmt.Println("\t[INFO] Created container, id : ", out.String())
	return out.String()

}
func DockerStopContainer(container_id string) {
	var out bytes.Buffer
	var stderr bytes.Buffer
	cmd := fmt.Sprintf("stop %s", container_id[:5]) // for some reason fully qualified container id is causing missing pages in docker daemon?!?
	cmd_ctx := exec.Command("docker", strings.Split(cmd, " ")...)
	cmd_ctx.Stdout = &out
	cmd_ctx.Stderr = &stderr
	err := cmd_ctx.Run()
	if err != nil {
		fmt.Println("[ERROR] Error stopping container...error stack : ")
		fmt.Println("[ERROR]", stderr.String())
		panic(err)
	}
}

func main() {
	fmt.Println("[NOTE] This orchestrator needs sudoless docker!!")
	fmt.Println("[NOTE] Every set has a fixed database constraint")
	fmt.Println("[INFO] Parsing config file...")
	dat, err := os.ReadFile("./config.json")
	if err != nil {
		println("err : ", err)
	}
	var dat_obj map[string]interface{}
	err = json.Unmarshal(dat, &dat_obj)
	if err != nil {
		println("err : ", err)
	} else {
		test := dat_obj["tests"].([]interface{})
		fmt.Println("")
		fmt.Println("")
		prev_gen_config := make(map[string]interface{})
		for i, test_interface := range test {
			fmt.Println("[INFO] running test set ", i+1, "...")
			test_obj := test_interface.(map[string]interface{})
			// dockerfile_path := test_obj["docker_file"].(string)
			// docker_image_name := test_obj["docker_image_name"].(string)
			docker_config := test_obj["docker_config"].(map[string]interface{})
			fmt.Println("\t[INFO] Starting docker containers with constraints...")
			// container_id := DockerBuildAndRun(dockerfile_path, docker_image_name, docker_config)
			tsbs_gen_config := test_obj["tsbs_gen_config"].(map[string]interface{})
			if prev_gen_config != nil && map_equality(prev_gen_config, tsbs_gen_config) {
				fmt.Println("\t[INFO] Reusing previously generated data...")
			} else {
				fmt.Println("\t[INFO] Generating data and queries...")
				// generate_cmd_from_tsbs_config(tsbs_gen_config)
			}
			// target := test_obj["target"].(string)
			tsbs_run_config := test_obj["tsbs_run_config"].(map[string]interface{})
			// run_cmd_from_tsbs_config(tsbs_run_config, target)
			fmt.Print("\t[INFO] Stopping docker containers...")
			// DockerStopContainer(container_id)
         parse_test(docker_config,tsbs_run_config)
			prev_gen_config = tsbs_gen_config
		}
	}

}


func parse_test(docker_cmd_opts map[string]interface{}, run_cmd_opts map[string]interface{}){
   output := `time,per. metric/s,metric total,overall metric/s,per. row/s,row total,overall row/s
1699960779,1479456.75,1.480760E+07,1479456.75,131883.82,1.320000E+06,131883.82
1699960789,1313726.14,2.793520E+07,1396658.41,117086.11,2.490000E+06,124490.94
1699960799,1312307.90,4.106520E+07,1368533.05,116938.33,3.660000E+06,121972.64
1699960809,1223649.16,5.329960E+07,1332322.81,109018.63,4.750000E+06,118735.10
1699960819,1291000.39,6.620920E+07,1324059.37,115003.60,5.900000E+06,117988.89
1699960829,1267844.76,7.888240E+07,1314694.23,113046.79,7.030000E+06,117165.56
1699960839,1246623.51,9.134840E+07,1304970.08,111002.09,8.140000E+06,116285.08
1699960849,1133238.71,1.026848E+08,1283497.11,100964.25,9.150000E+06,114369.40
1699960859,1200189.77,1.146832E+08,1274243.54,107031.19,1.022000E+07,113554.29
1699960869,1212570.80,1.268104E+08,1268075.64,107986.71,1.130000E+07,112997.47
1699960879,1132197.60,1.381396E+08,1255716.18,100935.60,1.231000E+07,111900.33
1699960889,1111316.57,1.492496E+08,1243686.89,99028.21,1.330000E+07,110828.01
1699960899,1156451.60,1.608076E+08,1236980.27,103058.07,1.433000E+07,110230.66
1699960909,1211370.79,1.729276E+08,1235150.14,107943.93,1.541000E+07,110067.24
1699960919,1145001.43,1.843732E+08,1229142.60,102039.34,1.643000E+07,109532.26
1699960929,1144659.33,1.958256E+08,1223859.93,101948.28,1.745000E+07,109058.04
1699960939,1234329.72,2.081624E+08,1224475.48,110057.93,1.855000E+07,109116.82
1699960949,1067402.31,2.188352E+08,1215750.19,95010.89,1.950000E+07,108333.25
1699960959,1189246.32,2.307284E+08,1214355.17,105993.43,2.056000E+07,108210.10
Summary:
loaded 232704000 metrics in 191.612sec with 10 workers (mean rate 1214454.98 metrics/sec)
loaded 20736000 rows in 191.612sec with 10 workers (mean rate 108218.76 rows/sec)`
   mocking_stdout := []byte(output)
   parse_load_results(bytes.NewBuffer(mocking_stdout),docker_cmd_opts, load_cmd_opts)
}
